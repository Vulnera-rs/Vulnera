# Vulnera Environment Configuration
# Copy this file to .env and fill in the values

# ============================================
# REQUIRED - Core Settings
# ============================================

# Database connection string
DATABASE_URL='postgresql://postgres:postgres@localhost:5432/vulnera'

# JWT secret for authentication (32+ characters)
VULNERA__AUTH__JWT_SECRET='your-minimum-32-character-secret-key-here'

# ============================================
# RECOMMENDED - Cache & Performance
# ============================================

# Dragonfly/Redis cache URL
VULNERA__CACHE__DRAGONFLY_URL='redis://127.0.0.1:6379'

# Analysis concurrency
VULNERA__ANALYSIS__MAX_CONCURRENT_PACKAGES=8

# ============================================
# LLM CONFIGURATION - AI-Powered Features
# ============================================

# Active LLM provider: google_ai, openai, or azure
VULNERA__LLM__PROVIDER='google_ai'

# Default model for LLM operations
VULNERA__LLM__DEFAULT_MODEL='gemini-2.0-flash'

# Temperature for generation (0.0 to 1.0)
VULNERA__LLM__TEMPERATURE=0.3

# Maximum tokens to generate
VULNERA__LLM__MAX_TOKENS=2048

# --- Google AI (Gemini) ---
# Get key from: https://aistudio.google.com/app/apikey
GOOGLE_AI_KEY=''
# Or via nested config:
# VULNERA__LLM__GOOGLE_AI__API_KEY=''

# --- OpenAI ---
# Get key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=''
# Optional: Organization ID
# VULNERA__LLM__OPENAI__ORGANIZATION_ID=''

# --- Azure OpenAI ---
# VULNERA__LLM__PROVIDER='azure'
# AZURE_OPENAI_KEY=''
# VULNERA__LLM__AZURE__ENDPOINT='https://your-resource.openai.azure.com'
# VULNERA__LLM__AZURE__DEPLOYMENT='gpt-4-deployment'
# VULNERA__LLM__AZURE__API_VERSION='2024-02-15-preview'

# --- LLM Resilience (Circuit Breaker + Retry) ---
VULNERA__LLM__RESILIENCE__ENABLED=true
VULNERA__LLM__RESILIENCE__MAX_RETRIES=3
VULNERA__LLM__RESILIENCE__INITIAL_BACKOFF_MS=500
VULNERA__LLM__RESILIENCE__CIRCUIT_BREAKER_THRESHOLD=5

# ============================================
# SANDBOX CONFIGURATION - Secure Module Execution
# ============================================

# Enable sandboxing for SAST/secrets modules (recommended for security)
VULNERA__SANDBOX__ENABLED=true

# Sandbox backend: auto, landlock, process, none
# - auto: Tries landlock (Linux 5.13+), falls back to process
# - landlock: Kernel-level isolation, near-zero overhead
# - process: Fork-based isolation, works on older kernels
# - none: Disable sandboxing (not recommended)
VULNERA__SANDBOX__BACKEND='auto'

# Execution timeout for sandboxed operations (seconds)
VULNERA__SANDBOX__EXECUTION_TIMEOUT_SECS=30

# Memory limit for sandboxed operations (MB)
VULNERA__SANDBOX__MEMORY_LIMIT_MB=256

# ============================================
# ENRICHMENT - AI Finding Enhancement
# ============================================

# Maximum findings to enrich per analysis (prioritized by severity)
VULNERA__LLM__ENRICHMENT__MAX_FINDINGS_TO_ENRICH=10

# Concurrent LLM calls for enrichment
VULNERA__LLM__ENRICHMENT__MAX_CONCURRENT_ENRICHMENTS=3

# Include code context in enrichment prompts
VULNERA__LLM__ENRICHMENT__INCLUDE_CODE_CONTEXT=true

# ============================================
# PRODUCTION SETTINGS
# ============================================

# Disable docs in production
# VULNERA__SERVER__ENABLE_DOCS=false

# Server address
VULNERA__SERVER__ADDRESS='0.0.0.0:3000'

# CORS origins (comma-separated)
# VULNERA__SERVER__CORS_ORIGINS='https://vulnera.studio'
